= How Fast are Parallel Programs?

=== How long does our computation take?

Performance: a key motivation for parallelism

어떻게 측정할 것인가?

- 실험에 의한 측정
- 점근적 분석

asymptotic analysis is important to understand how algorithms scale when

- inputs get larger
- we have more hardware parallelism available

=== Asymptotic analysis of sequential running time

You have previously learned how to concisely characterize behavior of sequential programs using the number of operations they perform as a function of arguments.

- inserting into an integer into a sorted linear list takes time O(n), for list storing n integers
- inserting into an integer into a balanced binary tree of n integers takes time O(log n), for tree storing n integers

[source,scala]
----
def sumSegment(a: Array[Int], p: Double, s: Int, t: Int): Int = {
  var i = s
  var sum: Int = 0
  while(i < t) {
    sum = sum + power(a(i), p)
    i = i + 1
  }
  sum
}
----

W(s, t) = O(t - s), a function of the form: c1(t - s) + c2

- t - s loop iterations
- a constant amount of work in each iteration

=== Analysis of recursive functions


[source,scala]
----
def segmentRec(a: Array[Int], p: Double, s: Int, t: Int) = {
  if(t -s < threshold)
    sumSegment(a, p, s, t)
  else {
    val m = s + (t - s)/2
    val (sum1, sum2) = (segmentRec(a, p, s, m),
                        segmentRec(a, p, m, t))
    sum1 + sum2
  }
}
----

재귀 호출은 아래와 같은 호출 트리로 설명할 수 있다.

image::../static/img/week1/performance-1.png[]

각각의 경우에 대한 수행시간은 아래와 같이 계산할 수 있다.

image::../static/img/week1/performance-2.png[]

image::../static/img/week1/performance-3.png[]

그래서 segmentRec 는 t - s에 대해 linear하다.

=== Recursive functions with unbounded parallelism

[source,scala]
----
def segmentRec(a: Array[Int], p: Double, s: Int, t: Int) = {
  if (t - s < threshold)
    sumSegment(a, p, s, t)
  else{
    val m = s + (t - s) / 2
    val (sum1, sum2) = parallel(segmentRec(a, p, s, m),
                                segmentRec(a, p, m, t))
    sum1 + sum2
  }
}
----

병렬처리로 하더라도 동일한 연산 트리를 가지며, 수행이 병렬로 수행되는 것이다.

image::../static/img/week1/performance-4.png[]

병렬로 수행할 경우 아래와 같이 수행시간을 계산할 수 있다.

image::../static/img/week1/performance-5.png[]

image::../static/img/week1/performance-6.png[]

그래서 D(s, t)는 O(log(t - s))라고 할 수 있다.


=== Work and depth

병렬 코드에 대해서 점근적 복잡도에 대해서 이야기하고 싶지만, 이는 병렬 자원에 의존적이다.

Work W(e): number of steps e would take if there was no parallelism

Depth D(e): number of steps if we had unbounded parallelism

=== Rules for depth (span) and work

W(parallel(e1, e2)) = W(e1) + W(e2) + c2
D(parallel(e1, e2)) = max(D(e1), D(e2)) + c1


=== Parallelism and Amdahl's Law

Suppose that we have two parts of a sequential computation:

- part1 takes fraction f of the computation time(e.g. 40%)
- part2 take the remaining 1 - f fraction of time(e.g. 60%) and we can speed up

If we make part2 P times faster the speedup is

image::../static/img/week1/performance-7.png[]

For P = 100 and f = 0.4 we obtain 2.46

Even if we speed the second part infinitely, we can obtain at most 1/0.4 = 2.5 speed up.
